{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOML EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.model import Model\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import ParallelRunStep, ParallelRunConfig\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "from azureml.train.automl import constants\n",
    "import onnxruntime\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS\n",
    "if \"models\" not in os.listdir():\n",
    "    os.mkdir(\"./models\")\n",
    "# OUTPUS\n",
    "if \"outputs\" not in os.listdir():\n",
    "    os.mkdir(\"./outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKSPACE AND EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load workspace   (DON'T FORGET TO DOWNLOAD CONFIG.JSON)\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment\n",
    "experiment_name = 'deployments-bankmarketing'\n",
    "project_folder = './deployments-project'\n",
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATASET AND PRESERVE DATA FOR INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and register it into Workspace unless itÂ´s already registered\n",
    "found = False\n",
    "key = \"BankMarketing Dataset\"\n",
    "description_text = \"Bank Marketing DataSet for Udacity Course 2\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        found = True\n",
    "        dataset = ws.datasets[key] \n",
    "\n",
    "if not found:\n",
    "    example_data = 'https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv'\n",
    "    dataset = Dataset.Tabular.from_delimited_files(example_data)        \n",
    "    dataset = dataset.register(workspace=ws,name=key,description=description_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep 0.1% of the data for batch inference\n",
    "train, examples = dataset.random_split(0.999,seed=42)\n",
    "# Drop y from inference sample\n",
    "examples = examples.drop_columns('y')"
   ]
  },
  {
   "source": [
    "# AUTOML EXPERIMENT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or load compute cluster\n",
    "cluster_name = \"aml-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_D12_V2', min_nodes=1, max_nodes=5)\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure AutoML\n",
    "automl_settings = {\"experiment_timeout_minutes\": 15,\n",
    "                    \"max_concurrent_iterations\": 5,\n",
    "                    \"primary_metric\" : 'AUC_weighted'}\n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\n",
    "                             task = \"classification\",\n",
    "                             training_data=train,\n",
    "                             label_column_name=\"y\",   \n",
    "                             path = project_folder,\n",
    "                             enable_early_stopping= True,\n",
    "                             featurization= 'auto',\n",
    "                             debug_log = \"automl_errors.log\",\n",
    "                             enable_onnx_compatible_models=True,\n",
    "                             **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the experiment and show details\n",
    "deployments_run = experiment.submit(automl_config, show_output = True)\n",
    "#RunDetails(deployments_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGISTER BEST MODEL AND BEST ONNX MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the best model\n",
    "model = deployments_run.register_model(model_name='deployments-bankmarketing')\n",
    "# Save the model\n",
    "best_run1, fitted_model = deployments_run.get_output()\n",
    "joblib.dump(fitted_model, filename='models/base_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best ONNX model\n",
    "best_run2, onnx_model = deployments_run.get_output(return_onnx_model=True)\n",
    "# Save the model\n",
    "onnx_path = \"./models/best_onnx.onnx\"\n",
    "OnnxConverter.save_onnx_model(onnx_model, onnx_path)\n",
    "# Register the model\n",
    "model_onnx = Model.register(workspace=ws, model_name='bankmarketing-onnx', model_path=onnx_path, model_framework=Model.Framework.ONNX,                                       model_framework_version='1.3')\n",
    "\n",
    "#service_name = 'onnx-bankmarketing'\n",
    "#service = Model.deploy(ws, service_name, [model_onnx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start inference session\n",
    "session = onnxruntime.InferenceSession(onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the inference\n",
    "try:\n",
    "    result = session.run([],data)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    result = str(e)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One data for ONNX                             #### USAR SOLO SI NO FUNCIONA LO ANTERIOR\n",
    "\n",
    "data1 =  {\n",
    "            \"age\": 17,\n",
    "            \"campaign\": 1,\n",
    "            \"cons.conf.idx\": -46.2,\n",
    "            \"cons.price.idx\": 92.893,\n",
    "            \"contact\": \"cellular\",\n",
    "            \"day_of_week\": \"mon\",\n",
    "            \"default\": \"no\",\n",
    "            \"duration\": 971,\n",
    "            \"education\": \"university.degree\",\n",
    "            \"emp.var.rate\": -1.8,\n",
    "            \"euribor3m\": 1.299,\n",
    "            \"housing\": \"yes\",\n",
    "            \"job\": \"blue-collar\",\n",
    "            \"loan\": \"yes\",\n",
    "            \"marital\": \"married\",\n",
    "            \"month\": \"may\",\n",
    "            \"nr.employed\": 5099.1,\n",
    "            \"pdays\": 999,\n",
    "            \"poutcome\": \"failure\",\n",
    "            \"previous\": 1\n",
    "          }\n",
    "\n",
    "@input_schema('inputs', PandasParameterType(input_sample))\n",
    "@output_schema(NumpyParameterType(output_sample))\n",
    "data = inputs[data1]\n",
    "assert isinstance(data, np.ndarray)\n",
    "\n",
    "pred = session.run([],data)  \n",
    "print(pred)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOCKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to build an image\n",
    "### NOTE: download the model and extract into ./models)\n",
    "model = Model(ws, 'deployments-bankmarketing')   \n",
    "env = Environment.from_conda_specification('docker', './models/conda_env_v_1_0_0.yml')\n",
    "inference_config = InferenceConfig(entry_script='./models/scoring_file_v_1_0_0.py', environment=env)         "
   ]
  },
  {
   "source": [
    "### BUILD AN IMAGE AND PULL IT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a standard image and pull it\n",
    "package = Model.package(ws, [model], inference_config)   \n",
    "package.wait_for_creation(show_output=True)    \n",
    "package.pull() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell should produce a result such as:\n",
    "\n",
    "Downloaded newer image for myworkspacef78fd10.azurecr.io/package:20190822181338.\n",
    "\n",
    "In git-bash run:\n",
    "\n",
    "\"docker images\"\n",
    "\n",
    "\"docker run -p 6789:5001 --name mycontainer imageID\" (replace id number)\n",
    "\n",
    "After the container is started, submit requests to http://localhost:6789/score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DOWNLAD FILES TO BUILD A LOCAL IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package with the dockerfile rather than the image\n",
    "package = model.package(ws, [], inference_config, generate_dockerfile=True)\n",
    "package.wait_for_creation(show_output=True)\n",
    "# Download the package.\n",
    "package.save(\"./imagefiles\")\n",
    "# Get the Azure container registry that the model/Dockerfile uses.\n",
    "acr=package.get_container_registry()\n",
    "print(\"Address:\", acr.address)\n",
    "print(\"Username:\", acr.username)\n",
    "print(\"Password:\", acr.password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In git-bash run:\n",
    "\n",
    "\"docker login (address) -u (username) -p (password)\"\n",
    "\n",
    "\"docker build --tag myimage imagefiles\" (replace imagefiles with the path were the image was saved)\n",
    "\n",
    "\"docker image\"\n",
    "\n",
    "\"docker run -p 6789:5001 --name mycontainer myimage:latest\"\n",
    "\n",
    "When finished run:\n",
    "\n",
    "\"docker kill mycontainer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the container   \n",
    " \n",
    "# Prepare 5 example data for Docker\n",
    "examples = examples.take(5).to_pandas_dataframe()\n",
    "data_docker = {\"data\":examples.to_json(orient='records')}                                         \n",
    "\n",
    "# URL for the web service.\n",
    "scoring_uri = 'http://localhost:6789/score'\n",
    "\n",
    "# Convert data to JSON string.\n",
    "input_data = json.dumps(data_docker)\n",
    "\n",
    "# Set the content type.\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# Make the request and display the response.\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BATCH SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default datastore\n",
    "datastore = ws.get_default_datastore()\n",
    "# output\n",
    "output_dir = PipelineData(name=\"scores\", datastore=datastore, output_path_on_compute=\"./results\")\n",
    "# environment\n",
    "env = Environment(name=\"deployments\")     \n",
    "# Prepare data for batch inference\n",
    "examples_batch = examples.as_named_input(\"examples_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel run configuration\n",
    "parallel_run_config = ParallelRunConfig(source_directory='.',\n",
    "                                        entry_script='batch_inference.py', \n",
    "                                        environment=env,\n",
    "                                        error_threshold=5,\n",
    "                                        output_action='append_row',\n",
    "                                        append_row_file_name=\"batch_inference.txt\",\n",
    "                                        compute_target=compute_target, \n",
    "                                        node_count=1)                       ## Try this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch scoring step    \n",
    "batch_score_step = ParallelRunStep(name=\"batch-scoring\",\n",
    "                                    inputs=[examples_batch],                            ## acÃ¡ estÃ¡ el problema\n",
    "                                    output=output_dir,\n",
    "                                    arguments=[\"--model_name\", 'deployments-bankmarketing'],  \n",
    "                                    parallel_run_config=parallel_run_config,\n",
    "                                    allow_reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the pipeline\n",
    "pipeline = Pipeline(workspace=ws, steps=[batch_score_step])\n",
    "batch_run = experiment.submit(pipeline)\n",
    "batch_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publish pipeline\n",
    "published_pipeline = batch_run.publish_pipeline(name=\"batch-scoring\", description=\"Batch scoring for project 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive authentication to get authentication header\n",
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "import requests\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENDPOINT FOR THE PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publish the pipeline to an endpoint\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, headers=auth_header, json={\"ExperimentName\": \"batch-scoring\"})\n",
    "run_id = response.json()[\"Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it again\n",
    "published_pipeline_run = PipelineRun(ws.experiments[\"batch-scoring\"], run_id)\n",
    "RunDetails(published_pipeline_run).show()"
   ]
  },
  {
   "source": [
    "## Explore results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "results = next(pipeline_run.get_children())\n",
    "batch_output = results.get_output_data(\"scores\")        ## esta linea puede traer problemas\n",
    "batch_output.download(local_path='./outputs')           ## esta linea puede traer problemas\n",
    "\n",
    "for root, dirs, files in os.walk('./outputs'):\n",
    "    for file in files:\n",
    "        if file.endswith(\"batch_inference.txt\"):\n",
    "            result_file = os.path.join(root, file)\n",
    " '''           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df = pd.read_csv(result_file, header=None)    # delimiter=\":\"\n",
    "df.columns = [\"age\",\"campaign\",\"cons.conf.idx\",\"cons.price.idx\",\"contact\",\"day_of_week\",\"default\",\"duration\",\"education\",\"emp.var.rate\",\n",
    "              \"euribor3m\",\"housing\",\"job\",\"loan\",\"marital\",\"month\",\"nr.employed\",\"pdays\",\"poutcome\",\"previous\",\"prediction\"]\n",
    "df.head(10)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}